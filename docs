ğŸ“˜ Educational Content Assistant
Retrieval-Augmented Generation (RAG) Application

  ğŸ“Œ Overview
The Educational Content Assistant is an AI-powered RAG-based system that allows users to upload educational documents (PDFs) and ask questions.
The assistant answers strictly based on the uploaded content, ensuring factual accuracy and preventing hallucinations.

This system is designed to be:
Lightweight
Beginner-friendly
Optimized for low-end hardware

ğŸ§  What is RAG?
Retrieval-Augmented Generation (RAG) combines:
Information Retrieval â€“ Fetch relevant document chunks
Text Generation â€“ Generate answers using an LLM
Instead of relying only on model memory, RAG grounds answers in real documents.

ğŸ—ï¸ System Architecture
High-Level Flow
flowchart LR
    User -->|Upload PDF| Frontend
    User -->|Ask Question| Frontend
    Frontend --> Backend
    Backend -->|Extract Text| DocumentProcessor
    DocumentProcessor -->|Chunks| VectorDB
    Backend -->|Query| VectorDB
    VectorDB -->|Relevant Chunks| Backend
    Backend -->|Prompt + Context| LLM
    LLM -->|Answer| Backend
    Backend --> Frontend

ğŸ§© Core Components
1ï¸âƒ£ Frontend (React)
PDF upload UI

Question input box
Chat-like answer display

Conversation history
2ï¸âƒ£ Backend (FastAPI)

API endpoints for:
PDF upload

Question answering
Secure API key handling
Orchestrates RAG pipeline

3ï¸âƒ£ Document Processor
PDF text extraction
Chunking text into smaller segments
Metadata tagging (page number, source)

4ï¸âƒ£ Vector Database
Stores document embeddings
Enables semantic similarity search
Returns top-k relevant chunks

5ï¸âƒ£ LLM (via OpenRouter / API)
Receives:
User question
Retrieved document context

  RAG Pipeline (Step-by-Step)
    sequenceDiagram
    participant U as User
    participant F as Frontend
    participant B as Backend
    participant V as Vector DB
    participant L as LLM
    U->>F: Upload PDF
    F->>B: Send PDF
    B->>B: Extract & Chunk Text
    B->>V: Store Embeddings
    U->>F: Ask Question
    F->>B: Send Question
    B->>V: Retrieve Similar Chunks
    V->>B: Relevant Context
    B->>L: Prompt + Context
    L->>B: Generated Answer
    B->>F: Display Answer

ğŸ›¡ï¸ Key Design Principles
âœ” Grounded Answers
Model is restricted to document context
Reduces hallucinations
âœ” Low Resource Usage
Chunking + vector search reduces token load
Runs on 4GB RAM / Intel i3
âœ” Secure API Handling
API keys stored only on backend
Never exposed to frontend

ğŸ“ Sample Prompt Template
You are an educational assistant.
Answer the question ONLY using the provided context.
If the answer is not present, say:
"I could not find this information in the uploaded document."

Context:
{retrieved_chunks}
Question:
{user_question}

ğŸ“Š Advantages of This RAG System
Accurate answers
Document-specific knowledge
Scalable to multiple PDFs
Cost-efficient
Ideal for students and educators

âš ï¸ Limitations
Cannot answer outside uploaded content
Performance depends on document quality
Large PDFs may require chunk tuning

ğŸš€ Future Enhancements
Multi-document support
Source citation per answer
OCR for scanned PDFs
User authentication
Conversation memory per document

  ğŸ“š Use Cases
Exam preparation
Lecture note Q&A
Research paper assistance
Internal knowledge base
E-learning platforms
Generates grounded responses
